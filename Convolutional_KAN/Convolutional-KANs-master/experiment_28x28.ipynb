{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annalisadipasquali/Desktop/Project AI MODELS/PAPERS/Convolutional-KANs-master/architectures_28x28\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T16:19:15.654178Z",
     "start_time": "2024-07-20T16:19:15.522790Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:20:14.678599Z",
     "start_time": "2024-07-20T16:20:12.755162Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from architectures_28x28.CKAN_BN import CKAN_BN\n",
    "from architectures_28x28.SimpleModels import *\n",
    "from architectures_28x28.ConvNet import ConvNet\n",
    "from architectures_28x28.KANConvs_MLP import KANC_MLP\n",
    "from architectures_28x28.KKAN import KKAN_Convolutional_Network\n",
    "from architectures_28x28.conv_and_kan import NormalConvsKAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:20:17.942894Z",
     "start_time": "2024-07-20T16:20:17.903478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformation \n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load MNIST and filtering for two classes \n",
    "mnist_train = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "mnist_test = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T16:20:20.088569Z",
     "start_time": "2024-07-20T16:20:20.002430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x304b21850>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print an image from the dataset \n",
    "plt.imshow(mnist_train[0][0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:20:29.103711Z",
     "start_time": "2024-07-20T16:20:29.097250Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        train_loader: DataLoader for training data\n",
    "        optimizer: the optimizer to use (e.g. SGD)\n",
    "        epoch: the current epoch\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: the average loss over the training set\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    # print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    Test the model\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "\n",
    "    Returns:\n",
    "        test_loss: the average loss over the test set\n",
    "        accuracy: the accuracy of the model on the test set\n",
    "        precision: the precision of the model on the test set\n",
    "        recall: the recall of the model on the test set\n",
    "        f1: the f1 score of the model on the test set\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (target == predicted).sum().item()\n",
    "\n",
    "            # Collect all targets and predictions for metric calculations\n",
    "            all_targets.extend(target.view_as(predicted).cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    precision = precision_score(all_targets, all_predictions, average='macro')\n",
    "    recall = recall_score(all_targets, all_predictions, average='macro')\n",
    "    f1 = f1_score(all_targets, all_predictions, average='macro')\n",
    "\n",
    "    # Normalize test loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Precision: {:.2f}, Recall: {:.2f}, F1 Score: {:.2f}\\n'.format(\n",
    "    #     test_loss, correct, len(test_loader.dataset), accuracy, precision, recall, f1))\n",
    "\n",
    "    return test_loss, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:20:34.476673Z",
     "start_time": "2024-07-20T16:20:34.471842Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_test_models(model, device, train_loader, test_loader, optimizer, criterion, epochs, scheduler):\n",
    "    \"\"\"\n",
    "    Train and test the model\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        train_loader: DataLoader for training data\n",
    "        test_loader: DataLoader for test data\n",
    "        optimizer: the optimizer to use (e.g. SGD)\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "        epochs: the number of epochs to train\n",
    "        scheduler: the learning rate scheduler\n",
    "\n",
    "    Returns:\n",
    "        all_train_loss: a list of the average training loss for each epoch\n",
    "        all_test_loss: a list of the average test loss for each epoch\n",
    "        all_test_accuracy: a list of the accuracy for each epoch\n",
    "        all_test_precision: a list of the precision for each epoch\n",
    "        all_test_recall: a list of the recall for each epoch\n",
    "        all_test_f1: a list of the f1 score for each epoch\n",
    "    \"\"\"\n",
    "    # Track metrics\n",
    "    all_train_loss = []\n",
    "    all_test_loss = []\n",
    "    all_test_accuracy = []\n",
    "    all_test_precision = []\n",
    "    all_test_recall = []\n",
    "    all_test_f1 = []\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train the model\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch, criterion)\n",
    "        all_train_loss.append(train_loss)\n",
    "        \n",
    "        # Test the model\n",
    "        test_loss, test_accuracy, test_precision, test_recall, test_f1 = test(model, device, test_loader, criterion)\n",
    "        all_test_loss.append(test_loss)\n",
    "        all_test_accuracy.append(test_accuracy)\n",
    "        all_test_precision.append(test_precision)\n",
    "        all_test_recall.append(test_recall)\n",
    "        all_test_f1.append(test_f1)\n",
    "\n",
    "        print(f'End of Epoch {epoch}: Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2%}')\n",
    "        scheduler.step()\n",
    "    model.all_test_accuracy = all_test_accuracy\n",
    "    model.all_test_precision = all_test_precision\n",
    "    model.all_test_f1 = all_test_f1\n",
    "    model.all_test_recall = all_test_recall\n",
    "\n",
    "    return all_train_loss, all_test_loss, all_test_accuracy, all_test_precision, all_test_recall, all_test_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:20:48.741032Z",
     "start_time": "2024-07-20T16:20:48.738818Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Models:\n",
    "- SimpleCNN\n",
    "- SimpleLinear\n",
    "- ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:21:26.076639Z",
     "start_time": "2024-07-20T16:20:57.036800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:09<00:00, 103.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1: Train Loss: 0.424062, Test Loss: 0.0022, Accuracy: 95.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:09<00:00, 102.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2: Train Loss: 0.126863, Test Loss: 0.0015, Accuracy: 96.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 934/938 [00:09<00:00, 103.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m scheduler_SimpleCNN \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mExponentialLR(optimizer_SimpleCNN, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m)\n\u001B[1;32m      5\u001B[0m criterion_SimpleCNN \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m----> 6\u001B[0m all_train_loss_SimpleCNN, all_test_loss_SimpleCNN, all_test_accuracy_SimpleCNN, all_test_precision_SimpleCNN, all_test_recall_SimpleCNN, all_test_f1_SimpleCNN \u001B[38;5;241m=\u001B[39m train_and_test_models(model_SimpleCNN, device, train_loader, test_loader, optimizer_SimpleCNN, criterion_SimpleCNN, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, scheduler\u001B[38;5;241m=\u001B[39mscheduler_SimpleCNN)\n",
      "Cell \u001B[0;32mIn[5], line 33\u001B[0m, in \u001B[0;36mtrain_and_test_models\u001B[0;34m(model, device, train_loader, test_loader, optimizer, criterion, epochs, scheduler)\u001B[0m\n\u001B[1;32m     29\u001B[0m all_test_f1 \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m train(model, device, train_loader, optimizer, epoch, criterion)\n\u001B[1;32m     34\u001B[0m     all_train_loss\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;66;03m# Test the model\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[4], line 29\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, device, train_loader, optimizer, epoch, criterion)\u001B[0m\n\u001B[1;32m     26\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Push the data forward through the model layers\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m output \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# Get the loss\u001B[39;00m\n\u001B[1;32m     32\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, target)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Project AI MODELS/PAPERS/Convolutional-KANs-master/architectures_28x28/SimpleModels.py:20\u001B[0m, in \u001B[0;36mSimpleCNN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 20\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x))\n\u001B[1;32m     21\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxpool(x)\n\u001B[1;32m     22\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_forward(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    457\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_SimpleCNN = SimpleCNN()\n",
    "model_SimpleCNN.to(device)\n",
    "optimizer_SimpleCNN = optim.AdamW(model_SimpleCNN.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_SimpleCNN = optim.lr_scheduler.ExponentialLR(optimizer_SimpleCNN, gamma=0.8)\n",
    "criterion_SimpleCNN = nn.CrossEntropyLoss()\n",
    "all_train_loss_SimpleCNN, all_test_loss_SimpleCNN, all_test_accuracy_SimpleCNN, all_test_precision_SimpleCNN, all_test_recall_SimpleCNN, all_test_f1_SimpleCNN = train_and_test_models(model_SimpleCNN, device, train_loader, test_loader, optimizer_SimpleCNN, criterion_SimpleCNN, epochs=10, scheduler=scheduler_SimpleCNN)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 28, 28]          640\n",
      "├─MaxPool2d: 1-2                         [-1, 64, 14, 14]          --\n",
      "├─Conv2d: 1-3                            [-1, 90, 14, 14]          51,930\n",
      "├─MaxPool2d: 1-4                         [-1, 90, 7, 7]            --\n",
      "├─Flatten: 1-5                           [-1, 4410]                --\n",
      "├─Linear: 1-6                            [-1, 10]                  44,110\n",
      "==========================================================================================\n",
      "Total params: 96,680\n",
      "Trainable params: 96,680\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 10.66\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.52\n",
      "Params size (MB): 0.37\n",
      "Estimated Total Size (MB): 0.89\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(SimpleCNN_Anna(), (1,28,28));"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T16:37:09.441065Z",
     "start_time": "2024-07-16T16:37:09.417004Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:47<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1: Train Loss: 0.137642, Test Loss: 0.0007, Accuracy: 98.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:41<00:00, 22.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2: Train Loss: 0.042339, Test Loss: 0.0006, Accuracy: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:43<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3: Train Loss: 0.028637, Test Loss: 0.0005, Accuracy: 99.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:43<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 4: Train Loss: 0.020072, Test Loss: 0.0005, Accuracy: 98.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:50<00:00, 18.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 5: Train Loss: 0.013740, Test Loss: 0.0004, Accuracy: 99.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:47<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 6: Train Loss: 0.010396, Test Loss: 0.0004, Accuracy: 99.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:49<00:00, 19.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 7: Train Loss: 0.007214, Test Loss: 0.0004, Accuracy: 99.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:48<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 8: Train Loss: 0.005327, Test Loss: 0.0004, Accuracy: 99.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:46<00:00, 20.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 9: Train Loss: 0.003844, Test Loss: 0.0005, Accuracy: 99.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:40<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 10: Train Loss: 0.002992, Test Loss: 0.0004, Accuracy: 99.19%\n"
     ]
    }
   ],
   "source": [
    "model_SimpleCNN = SimpleCNN_Anna()\n",
    "model_SimpleCNN.to(device)\n",
    "optimizer_SimpleCNN = optim.AdamW(model_SimpleCNN.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_SimpleCNN = optim.lr_scheduler.ExponentialLR(optimizer_SimpleCNN, gamma=0.8)\n",
    "criterion_SimpleCNN = nn.CrossEntropyLoss()\n",
    "all_train_loss_SimpleCNN, all_test_loss_SimpleCNN, all_test_accuracy_SimpleCNN, all_test_precision_SimpleCNN, all_test_recall_SimpleCNN, all_test_f1_SimpleCNN = train_and_test_models(model_SimpleCNN, device, train_loader, test_loader, optimizer_SimpleCNN, criterion_SimpleCNN, epochs=10, scheduler=scheduler_SimpleCNN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T16:45:18.832547Z",
     "start_time": "2024-07-16T16:37:13.322560Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x1200 with 64 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stampo i filtri del primo livello \n",
    "\n",
    "model = model_SimpleCNN\n",
    "\n",
    "# Estrai i pesi del primo livello di convoluzione\n",
    "filters = model.conv1.weight.data\n",
    "\n",
    "# Definisci il numero di filtri da visualizzare\n",
    "n_filters = filters.shape[0]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "for i in range(n_filters):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(filters[i, 0, :, :].cpu(), cmap='grey')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T11:43:48.603274Z",
     "start_time": "2024-07-15T11:43:47.988210Z"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x31e2d48d0>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((1 - filters[0, 0, :, :].cpu()), cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T11:32:47.095728Z",
     "start_time": "2024-07-15T11:32:47.032437Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:23:37.914730Z",
     "start_time": "2024-07-15T11:23:34.982344Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 265/938 [00:02<00:07, 93.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m scheduler_SimpleCNN_2 \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mExponentialLR(optimizer_SimpleCNN_2, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m)\n\u001B[1;32m      5\u001B[0m criterion_SimpleCNN_2 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m----> 6\u001B[0m all_train_loss_SimpleCNN_2, all_test_loss_SimpleCNN_2, all_test_accuracy_SimpleCNN_2, all_test_precision_SimpleCNN_2, all_test_recall_SimpleCNN_2, all_test_f1_SimpleCNN_2 \u001B[38;5;241m=\u001B[39m train_and_test_models(model_SimpleCNN_2, device, train_loader, test_loader, optimizer_SimpleCNN_2, criterion_SimpleCNN_2, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, scheduler\u001B[38;5;241m=\u001B[39mscheduler_SimpleCNN_2)\n",
      "Cell \u001B[0;32mIn[5], line 33\u001B[0m, in \u001B[0;36mtrain_and_test_models\u001B[0;34m(model, device, train_loader, test_loader, optimizer, criterion, epochs, scheduler)\u001B[0m\n\u001B[1;32m     29\u001B[0m all_test_f1 \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m train(model, device, train_loader, optimizer, epoch, criterion)\n\u001B[1;32m     34\u001B[0m     all_train_loss\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;66;03m# Test the model\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[4], line 29\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, device, train_loader, optimizer, epoch, criterion)\u001B[0m\n\u001B[1;32m     26\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Push the data forward through the model layers\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m output \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# Get the loss\u001B[39;00m\n\u001B[1;32m     32\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, target)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Convolutional-KANs-master/architectures_28x28/SimpleModels.py:42\u001B[0m, in \u001B[0;36mSimpleCNN_2.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 42\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x))\n\u001B[1;32m     43\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxpool(x)\n\u001B[1;32m     44\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_forward(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    457\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_SimpleCNN_2 = SimpleCNN_2()\n",
    "model_SimpleCNN_2.to(device)\n",
    "optimizer_SimpleCNN_2 = optim.AdamW(model_SimpleCNN_2.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_SimpleCNN_2 = optim.lr_scheduler.ExponentialLR(optimizer_SimpleCNN_2, gamma=0.8)\n",
    "criterion_SimpleCNN_2 = nn.CrossEntropyLoss()\n",
    "all_train_loss_SimpleCNN_2, all_test_loss_SimpleCNN_2, all_test_accuracy_SimpleCNN_2, all_test_precision_SimpleCNN_2, all_test_recall_SimpleCNN_2, all_test_f1_SimpleCNN_2 = train_and_test_models(model_SimpleCNN_2, device, train_loader, test_loader, optimizer_SimpleCNN_2, criterion_SimpleCNN_2, epochs=10, scheduler=scheduler_SimpleCNN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SimpleLinear = SimpleLinear()\n",
    "model_SimpleLinear.to(device)\n",
    "optimizer_SimpleLinear = optim.AdamW(model_SimpleLinear.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_SimpleLinear = optim.lr_scheduler.ExponentialLR(optimizer_SimpleLinear, gamma=0.8)\n",
    "criterion_SimpleLinear = nn.CrossEntropyLoss()\n",
    "all_train_loss_SimpleLinear, all_test_loss_SimpleLinear, all_test_accuracy_SimpleLinear, all_test_precision_SimpleLinear, all_test_recall_SimpleLinear, all_test_f1_SimpleLinear = train_and_test_models(model_SimpleLinear, device, train_loader, test_loader, optimizer_SimpleLinear, criterion_SimpleLinear, epochs=10, scheduler=scheduler_SimpleLinear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ConvNet = ConvNet()\n",
    "model_ConvNet.to(device)\n",
    "optimizer_ConvNet = optim.AdamW(model_ConvNet.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_ConvNet = optim.lr_scheduler.ExponentialLR(optimizer_ConvNet, gamma=0.8)\n",
    "criterion_ConvNet = nn.CrossEntropyLoss()\n",
    "all_train_loss_ConvNet, all_test_loss_ConvNet, all_test_accuracy_ConvNet, all_test_precision_ConvNet, all_test_recall_ConvNet, all_test_f1_ConvNet = train_and_test_models(model_ConvNet, device, train_loader, test_loader, optimizer_ConvNet, criterion_ConvNet, epochs=10, scheduler=scheduler_ConvNet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_KKAN_Convolutional_Network = KKAN_Convolutional_Network(device = device)\n",
    "model_KKAN_Convolutional_Network.to(device)\n",
    "optimizer_KKAN_Convolutional_Network = optim.AdamW(model_KKAN_Convolutional_Network.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_KKAN_Convolutional_Network = optim.lr_scheduler.ExponentialLR(optimizer_KKAN_Convolutional_Network, gamma=0.8)\n",
    "criterion_KKAN_Convolutional_Network = nn.CrossEntropyLoss()\n",
    "\n",
    "all_train_loss_KKAN_Convolutional_Network, all_test_loss_KKAN_Convolutional_Network, all_test_accuracy_KKAN_Convolutional_Network, all_test_precision_KKAN_Convolutional_Network, all_test_recall_KKAN_Convolutional_Network, all_test_f1_KKAN_Convolutional_Network = train_and_test_models(model_KKAN_Convolutional_Network, device, train_loader, test_loader, optimizer_KKAN_Convolutional_Network, criterion_KKAN_Convolutional_Network, epochs=10, scheduler=scheduler_KKAN_Convolutional_Network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_KANC_MLP= KANC_MLP(device = device)\n",
    "model_KANC_MLP.to(device)\n",
    "optimizer_KANC_MLP = optim.AdamW(model_KANC_MLP.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_KANC_MLP = optim.lr_scheduler.ExponentialLR(optimizer_KANC_MLP, gamma=0.8)\n",
    "criterion_KANC_MLP = nn.CrossEntropyLoss()\n",
    "\n",
    "all_train_loss_KANC_MLP, all_test_loss_KANC_MLP, all_test_accuracy_KANC_MLP, all_test_precision_KANC_MLP, all_test_recall_KANC_MLP, all_test_f1_KANC_MLP = train_and_test_models(model_KANC_MLP, device, train_loader, test_loader, optimizer_KANC_MLP, criterion_KANC_MLP, epochs=10, scheduler=scheduler_KANC_MLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Convs_and_KAN= NormalConvsKAN()\n",
    "model_Convs_and_KAN.to(device)\n",
    "optimizer_Convs_and_KAN = optim.AdamW(model_Convs_and_KAN.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler_Convs_and_KAN = optim.lr_scheduler.ExponentialLR(optimizer_Convs_and_KAN, gamma=0.8)\n",
    "criterion_Convs_and_KAN = nn.CrossEntropyLoss()\n",
    "\n",
    "all_train_loss_Convs_and_KAN, all_test_loss_Convs_and_KAN, all_test_accuracy_Convs_and_KAN, all_test_precision_Convs_and_KAN, all_test_recall_Convs_and_KAN, all_test_f1_Convs_and_KAN = train_and_test_models(model_Convs_and_KAN, device, train_loader, test_loader, optimizer_Convs_and_KAN, criterion_Convs_and_KAN, epochs=10, scheduler=scheduler_Convs_and_KAN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))  \n",
    "\n",
    "ax1.plot(all_test_loss_SimpleCNN, label='Loss ConvNet(Small)', color='red')\n",
    "ax1.plot(all_test_loss_SimpleLinear, label='Loss 1 Layer & MLP', color='green')\n",
    "ax1.plot(all_test_loss_SimpleCNN_2, label='Loss ConvNet(Medium)', color='yellow')\n",
    "ax1.plot(all_test_loss_ConvNet, label='Loss ConvNet (Big)', color='purple')\n",
    "ax1.plot(all_test_loss_KANC_MLP, label='Loss KANConv & MLP', color='blue')\n",
    "ax1.plot(all_test_loss_Convs_and_KAN, label='Loss Conv & KAN', color='gray')\n",
    "ax1.plot(all_test_loss_KKAN_Convolutional_Network, label='Loss KKAN', color='orange')\n",
    "\n",
    "ax1.set_title('Loss Test vs Epochs')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.scatter(count_parameters(model_SimpleCNN), max(all_test_accuracy_SimpleCNN), color='red', label='ConvNet (Small)')\n",
    "ax2.scatter(count_parameters(model_SimpleLinear), max(all_test_accuracy_SimpleLinear), color='green', label='1 Layer MLP')\n",
    "ax2.scatter(count_parameters(model_SimpleCNN_2), max(all_test_accuracy_SimpleCNN_2), color='yellow', label='ConvNet (Medium)')\n",
    "ax2.scatter(count_parameters(model_ConvNet), max(all_test_accuracy_ConvNet), color='purple', label='ConvNet (Big)')\n",
    "ax2.scatter(count_parameters(model_KANC_MLP), max(all_test_accuracy_KANC_MLP), color='blue', label='KANConv & MLP')\n",
    "ax2.scatter(count_parameters(model_Convs_and_KAN), max(all_test_accuracy_Convs_and_KAN), color='grey', label='Convs & KAN')\n",
    "ax2.scatter(count_parameters(model_KKAN_Convolutional_Network), max(all_test_accuracy_KKAN_Convolutional_Network), color='orange', label='KKAN')\n",
    "\n",
    "ax2.set_title('Number of Parameters vs Accuracy')\n",
    "ax2.set_xlabel('Number of Parameters')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend() \n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "# Listas para acumular datos\n",
    "accs = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1s = []\n",
    "params_counts = []\n",
    "\n",
    "# Modelos y sus métricas correspondientes\n",
    "models = [model_SimpleLinear, model_SimpleCNN,model_SimpleCNN_2, model_ConvNet, model_KANC_MLP, model_Convs_and_KAN, model_KKAN_Convolutional_Network]\n",
    "# all_accuracys = [all_test_accuracy_SimpleLinear, all_test_accuracy_SimpleCNN, all_test_accuracy_ConvNet, all_test_accuracy_KANC_MLP, all_test_accuracy_Convs_and_KAN, all_test_accuracy_KKAN_Convolutional_Network]\n",
    "# all_precision = [all_test_precision_SimpleLinear, all_test_precision_SimpleCNN, all_test_precision_ConvNet, all_test_precision_KANC_MLP, all_test_precision_Convs_and_KAN, all_test_precision_KKAN_Convolutional_Network]\n",
    "# all_recall = [all_test_recall_SimpleLinear, all_test_recall_SimpleCNN, all_test_recall_ConvNet, all_test_recall_KANC_MLP, all_test_recall_Convs_and_KAN, all_test_recall_KKAN_Convolutional_Network]\n",
    "# all_f1s = [all_test_f1_SimpleLinear, all_test_f1_SimpleCNN, all_test_f1_ConvNet, all_test_f1_KANC_MLP, all_test_f1_Convs_and_KAN, all_test_f1_KKAN_Convolutional_Network]\n",
    "\n",
    "\n",
    "# Recopilación de datos\n",
    "for i, m in enumerate(models):\n",
    "    index = np.argmax(m.all_test_accuracy)\n",
    "    params_counts.append(count_parameters(m))\n",
    "    accs.append(m.all_test_accuracy[index])\n",
    "    precision.append(m.all_test_precision[index])\n",
    "    recall.append(m.all_test_recall[index])\n",
    "    f1s.append(m.all_test_f1[index])\n",
    "\n",
    "# Creación del DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Test Accuracy\": accs,\n",
    "    \"Test Precision\": precision,\n",
    "    \"Test Recall\": recall,\n",
    "    \"Test F1 Score\": f1s,\n",
    "    \"Number of Parameters\": params_counts\n",
    "}, index=[\"1 Layer MLP\", \"ConvNet (Small)\",\"ConvNet (Medium)\", \"ConvNet (Big)\", \"KANConv & MLP\", \"Simple Conv & KAN\", \"KKAN\"])\n",
    "\n",
    "df.to_csv('experiment_28x28.csv', index=False)\n",
    "\n",
    "# Aplicando el estilo\n",
    "df_styled = df.style.apply(highlight_max, subset=df.columns[:], axis=0).format('{:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
